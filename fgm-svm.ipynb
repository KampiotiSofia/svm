{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "from numpy import linalg as LA\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_moons, make_circles, make_classification \n",
    "from sklearn import metrics\n",
    "from sklearn import linear_model\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.utils import shuffle\n",
    "from dask.distributed import Pub, Sub, TimeoutError\n",
    "from dask.distributed import get_worker,wait\n",
    "import dask\n",
    "import dask.array as da\n",
    "import statistics\n",
    "import math \n",
    "import asyncio\n",
    "import time\n",
    "import random\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dask client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Client</h3>\n",
       "<ul style=\"text-align: left; list-style: none; margin: 0; padding: 0;\">\n",
       "  <li><b>Scheduler: </b>tcp://127.0.0.1:43472</li>\n",
       "  <li><b>Dashboard: </b><a href='http://127.0.0.1:8787/status' target='_blank'>http://127.0.0.1:8787/status</a>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Cluster</h3>\n",
       "<ul style=\"text-align: left; list-style:none; margin: 0; padding: 0;\">\n",
       "  <li><b>Workers: </b>5</li>\n",
       "  <li><b>Cores: </b>5</li>\n",
       "  <li><b>Memory: </b>33.69 GB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: 'tcp://127.0.0.1:43472' processes=5 threads=5, memory=33.69 GB>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dask.distributed import Client , LocalCluster\n",
    "\n",
    "cluster = LocalCluster(n_workers=5, threads_per_worker=1)\n",
    "client = Client(cluster)\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Î‘ssign each worker to a local name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "c=cluster.scheduler.workers\n",
    "worker1= c.items()[0][0]\n",
    "worker2= c.items()[1][0]\n",
    "worker3= c.items()[2][0]\n",
    "worker4= c.items()[3][0]\n",
    "worker5= c.items()[4][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pub-Sub structure\n",
    "***\n",
    "### Coordinator\n",
    "Coordinator is used by a future, in specific worker (worker1).First send E if E=0,askes workers to compute local drifts in order to update E.This future ends every time that we get a new E. Starts again till workers have no chunks to read "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coordinator(n_workers,E):\n",
    "    pub_init = Pub('Initialize')\n",
    "    pub_th = Pub('Theta')\n",
    "    pub_endr = Pub('EndRound')\n",
    "    pub_endsub = Pub('EndSubRound')\n",
    "    sub_incr = Sub('Increment')\n",
    "    sub_f = Sub('Fs')\n",
    "    sub_x = Sub('Xs')\n",
    "    #--------------------------------Useful functions------------------------------------\n",
    "    def get_incr():    \n",
    "        try:\n",
    "            incr=sub_incr.get(timeout=15)\n",
    "            return incr\n",
    "        except TimeoutError:\n",
    "            print('Increment aknowlegment not received')\n",
    "            return -10\n",
    "    def get_fi():  \n",
    "        fis=[]\n",
    "        try:\n",
    "            fi=sub_f.get()\n",
    "            fis.append(fi)\n",
    "            for i in range(3):\n",
    "                fi=sub_f.get() \n",
    "                fis.append(fi)\n",
    "            return fis\n",
    "        except:\n",
    "            print('Fi aknowlegment not received')\n",
    "            return -10\n",
    "    def get_xi():  \n",
    "        drifts=[]\n",
    "        try:\n",
    "            xi=sub_x.get()\n",
    "            drifts.append(xi)\n",
    "            for i in range(3):\n",
    "                xi=sub_x.get() \n",
    "                drifts.append(xi)\n",
    "            return drifts\n",
    "        except:\n",
    "            print('Xi aknowlegment not received')\n",
    "            return -10\n",
    "    def longest(l):\n",
    "        max_len=0\n",
    "        for i in l:\n",
    "            if len(i)>max_len:\n",
    "                max_len=len(i)\n",
    "        return max_len\n",
    "    \n",
    "    def add_x(array):\n",
    "        \n",
    "        length=longest(array)\n",
    "        sum_x=[0]*length\n",
    "        for x in array:\n",
    "            dif=length-len(x)\n",
    "            for i in range(dif):\n",
    "                x=np.append(x,0)\n",
    "            sum_x=np.add(sum_x,x)\n",
    "        return sum_x\n",
    "    \n",
    "    def add_f(array):\n",
    "        sum_x=0\n",
    "        for x in array:\n",
    "            sum_x=sum_x+x\n",
    "        return sum_x\n",
    "    #------------------------------Start coordinator--------------------------------------\n",
    "    while len(pub_init.subscribers)!=4:\n",
    "        #if not all workers subscribe sleep\n",
    "        time.sleep(0.01)\n",
    "    \n",
    "    counter=0\n",
    "    count_sub=0\n",
    "    k=n_workers\n",
    "    th=0\n",
    "#     c=0\n",
    "    fis=0\n",
    "    drifts=0\n",
    "    sum_xi=0\n",
    "    incr=0\n",
    "    e_y=0.01\n",
    "    print(\"Coo started\")\n",
    "    if E is 0: #if E=0 we need to update E\n",
    "        pub_init.put(None) \n",
    "        drifts=get_xi() #get local drifts (Xi's)\n",
    "        sum_xi=add_x(drifts)\n",
    "        E=E+sum_xi\n",
    "        pub_init.put(E)\n",
    "    else:\n",
    "        pub_init.put(E)\n",
    "    \n",
    "    print(\"E\",E)\n",
    "    y=k*f([0],E)\n",
    "    subs=[]\n",
    "    flag=True #use this flag to finish future if chunks are out\n",
    "    while y<=e_y*k*f([0],E): #start of the round\n",
    "        \n",
    "        counter=counter+1\n",
    "        print(\"START ROUND:\",counter)\n",
    "        th=-y/(2*k)\n",
    "        print(\"th\",th)\n",
    "        \n",
    "        pub_endr.put(1) #let worker know that a new round begins\n",
    "        pub_th.put(th) #send theta\n",
    "        \n",
    "        c=0\n",
    "        fis=[]\n",
    "        count_sub=0\n",
    "        \n",
    "        while c<k: #start of the subround\n",
    "            \n",
    "            count_sub=count_sub+1\n",
    "            print(\"START SUBROUND:\",count_sub)\n",
    "            \n",
    "            pub_endsub.put(1) #let worker know that a new subround begins\n",
    "            incr=get_incr() #Get increments\n",
    "#             print(\"incr\")\n",
    "            if type(incr)==str: # works as a flag to let coordinator know that chunks are out\n",
    "                print(\"Coo received notice of chunks ended...\")\n",
    "#                 pub_endsub.put(0)\n",
    "                flag=False \n",
    "                break\n",
    "            if incr==-10:\n",
    "                incr=0\n",
    "            \n",
    "            c=c+incr\n",
    "            print(\"c,incr\",c,incr)\n",
    "#-----------------------------subrounds ended---------------------------------------------\n",
    "        if flag==False: #if false chunks are out end future\n",
    "#             pub_endsub.put(0)\n",
    "            pub_endsub.put(0)\n",
    "            break\n",
    "    \n",
    "        pub_endsub.put(0) #let workers know that subrounds ended \n",
    "        fis=get_fi() #get F(Xi)'s from workers\n",
    "        \n",
    "        y=add_f(fis)\n",
    "        print(\"y\",y)\n",
    "#-----------------------------rounds ended-------------------------------------------------\n",
    "    pub_endr.put(0) #let workers know that rounds ended \n",
    "    \n",
    "    drifts=get_xi() #get local drifts (Xi's)\n",
    "    sum_xi=add_x(drifts)\n",
    "    E=E+sum_xi\n",
    "        \n",
    "    print(\"Coo ended...\")\n",
    "    return E,counter,count_sub\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Worker\n",
    "***\n",
    "Worker function is used in multiple future (here 4), each one is assigned in a different cluster worker.Workers run till there are now more chunks.There are now results needed from this futures so, there is no need to restart them (like we do with the coordinator). Each worker reads a different file to update Si. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def worker_f(name,Si,clf):\n",
    "    sub_init = Sub('Initialize')\n",
    "    sub_th = Sub('Theta')\n",
    "    sub_endr = Sub('EndRound')\n",
    "    sub_endsub = Sub('EndSubRound')\n",
    "    pub_incr = Pub('Increment')\n",
    "    pub_f = Pub('Fs')\n",
    "    pub_x = Pub('Xs')\n",
    "    #--------------------------------Useful functions------------------------------------\n",
    "    def get_init():    \n",
    "        try:\n",
    "            init=sub_init.get(timeout=100)\n",
    "            return init\n",
    "        except TimeoutError:\n",
    "            print('Init aknowlegment not received')\n",
    "            return []\n",
    "        \n",
    "    def get_th():    \n",
    "        try:\n",
    "            th=sub_th.get(timeout=100)\n",
    "            return th\n",
    "        except TimeoutError:\n",
    "            print('Theta aknowlegment not received')\n",
    "            return -10\n",
    "        \n",
    "    def get_endr():\n",
    "        try:\n",
    "            endr=sub_endr.get(timeout=100)\n",
    "            return endr\n",
    "        except TimeoutError:\n",
    "            print('EndofRound aknowlegment not received')\n",
    "            return -10\n",
    "    \n",
    "    def get_endsub():\n",
    "        try:\n",
    "            endsub=sub_endsub.get(timeout=100)\n",
    "            return endsub\n",
    "        except TimeoutError:\n",
    "            print('EndofSubRound aknowlegment not received')\n",
    "            return -10\n",
    "        \n",
    "    def make_same(x1,x2):\n",
    "        if len(x1)!=len(x2):\n",
    "            dif=len(x2)-len(x1)\n",
    "            \n",
    "            for i in range(abs(dif)):\n",
    "                if dif>0:\n",
    "                    x1=np.append(x1,10)\n",
    "                else:\n",
    "\n",
    "                    x2=np.append(x2,0)\n",
    "        return x1,x2\n",
    "    #--------------------------------Start of worker------------------------------------\n",
    "    start=False\n",
    "    th=0\n",
    "    w_id= get_worker().name #get worker id\n",
    "    f_name=\"sample\"+str(w_id)+\".txt\" # concat sample with the w_id to get file name\n",
    "    flag=True \n",
    "    E=[]\n",
    "    Xi=[]\n",
    "    \n",
    "    count_chunks=1\n",
    "    while flag==True: #while this flag stays true there are chunks\n",
    "        \n",
    "        E=get_init() # get E from coordinator\n",
    "\n",
    "        if E is None: #if E=0 compute Xi and return Xi to update E\n",
    "            X,y=get_chunk(count_chunks) #get_newSi(count_chunks,f_name)\n",
    "            if type(X)==str and type(y)==str:\n",
    "                flag=False\n",
    "                print(\"NO Chunks,hey\")\n",
    "                break\n",
    "            clf.partial_fit(X,y,np.unique(([0,1])))\n",
    "            Si = clf.coef_[0]\n",
    "            Xi=Si\n",
    "            pub_x.put(Xi)\n",
    "            E=get_init()\n",
    "\n",
    "#----------------------------------begin of round----------------------------------------\n",
    "        while get_endr()==1: \n",
    "            ci=0\n",
    "            Xi=[0]\n",
    "\n",
    "            th=get_th() #get theta\n",
    "\n",
    "            if th==-10:\n",
    "                break\n",
    "#----------------------------------begin of subround----------------------------------------\n",
    "            while get_endsub()==1:\n",
    "\n",
    "                count_chunks=count_chunks+1\n",
    "\n",
    "                zi=f(Xi,E)\n",
    "                X,y=get_chunk(count_chunks) #get_newSi(count_chunks,f_name)\n",
    "                if type(X)==str and type(y)==str:\n",
    "                    flag=False\n",
    "                    print(\"NO Chunks\")\n",
    "                    pub_incr.put(\"no\")\n",
    "                else:\n",
    "                \n",
    "                    clf.partial_fit(X,y,np.unique([0,1]))\n",
    "                    new=clf.coef_[0]\n",
    "\n",
    "                    Si,new=make_same(Si,new) #read from the file\n",
    "                    S_prev=Si \n",
    "                    Si=np.add(Si,new)\n",
    "                    Xi=Si-S_prev\n",
    "                    print(w_id,\"Xi\",Xi)\n",
    "                    c_th=0 \n",
    "\n",
    "                    if th!=0: #avoid division with 0 if th=0 c_th=0\n",
    "                        c_th=(f(Xi,E)-zi)/th\n",
    "                    print(w_id,\"c_th\",c_th)\n",
    "                    ci_new=max(ci,math.floor(c_th))\n",
    "                    print(w_id,\"ci\",ci,\"new ci\",ci_new)\n",
    "                    if ci!=ci_new: #if we detect a difference send it to the coordinator\n",
    "                        ci=ci_new\n",
    "                        pub_incr.put(ci)\n",
    "    #                 else:\n",
    "    #                     pub_incr.put(0)\n",
    "                        print(w_id,\"Sended...\",ci)\n",
    "#----------------------------------end of subround----------------------------------------\n",
    "#             if flag==False: #if flag is false let coordinator know\n",
    "#                 pub_incr.put(\"no\")\n",
    "#                 print(\"No chunks, end of round\")\n",
    "#                 time.sleep(3)\n",
    "#                 break\n",
    "            \n",
    "            pub_f.put(f(Xi,E)) \n",
    "#-------------------------------end of round----------------------------------------\n",
    "        time.sleep(4)\n",
    "        pub_x.put(Xi) # send Xi    \n",
    "    #time.sleep(3)\n",
    "    print(w_id,\"Ended...\")\n",
    "    return Si\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions\n",
    "***\n",
    "### Î¦(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.035003121099842716\n"
     ]
    }
   ],
   "source": [
    "def f(x,E):\n",
    "    if len(x)!=len(E):\n",
    "        dif=len(E)-len(x)\n",
    "        for i in range(abs(dif)):\n",
    "            if dif>0:\n",
    "                x=np.append(x,0)\n",
    "            else:\n",
    "                E=np.append(E,0)\n",
    "    if LA.norm(E)!=0:\n",
    "        \n",
    "        t1= -0.01*LA.norm(E)-np.dot(x,(E/LA.norm(E)))\n",
    "    else:\n",
    "        t1=0\n",
    "    n_sum=np.add(x,E)\n",
    "    t2=LA.norm(n_sum) - (1+0.01)*LA.norm(E)\n",
    "    return max(t1,t2)\n",
    "print(f([0.1,0,0.1,0.1,0,0,0.1,0,0,0,0,0,0,0],[0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get new Si \n",
    "***\n",
    "Read from file a spesific line and convert the string to np.array\n",
    "\n",
    "file form: [0,0,0,0,0,0,0,0,0,0,0] [0,0,0,0,0,0,0,0,0,0,0.1]... 20 line each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_newSi(x,f_name):\n",
    "    fp = open(f_name)\n",
    "    l=None    \n",
    "    for i, line in enumerate(fp):\n",
    "        if line in ['\\n', '\\r\\n']: #exclude [ ,]\n",
    "            break\n",
    "        if i == x-1:\n",
    "            l=re.sub('\\]|\\[','', line)\n",
    "            l= list(l.split(\",\")) #split string\n",
    "            for i in range(len(l)): #convert from char to float\n",
    "                l[i] = float(l[i])\n",
    "            break      \n",
    "    fp.close()\n",
    "    return l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Chunk \n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_chunk(n):\n",
    "    X=np.load(\"X.npy\")\n",
    "    y=np.load(\"y.npy\")\n",
    "    n=n-1\n",
    "    n_parts=200\n",
    "    split= int(len(X)/n_parts)\n",
    "    start=split*n\n",
    "    end=start+split\n",
    "    if start>=(len(X)-1):\n",
    "        return \"False\",\"False\"\n",
    "    if end>(len(X)-1):\n",
    "        end=len(X)\n",
    "    X_train = X[start:end]\n",
    "    y_train = y[start:end]\n",
    "    return X_train,y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Future start function \n",
    "***\n",
    "Starts 4 workers and one coordinator worker "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def future_start(E,Si,clf):\n",
    "    coo= client.submit(coordinator,4,E,workers=worker1)\n",
    "    w1=client.submit(worker_f,1,Si[0],clf,workers=worker2)\n",
    "    w2=client.submit(worker_f,2,Si[1],clf, workers=worker3)\n",
    "    w3=client.submit(worker_f,3,Si[2],clf, workers=worker4)\n",
    "    w4=client.submit(worker_f,4,Si[3],clf, workers=worker5)\n",
    "    return coo,w1,w2,w3,w4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import traceback\n",
    "def main():\n",
    "    #user_input=input(\"Enter\")\n",
    "    #make a dataset and save training X and y \n",
    "    X, y = make_classification(n_samples=1200, n_features=4,n_classes=2)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "    np.save(\"X\", X_train)\n",
    "    np.save(\"y\", y_train)\n",
    "    np.save(\"X_test\", X_test)\n",
    "    np.save(\"y_test\", y_test)\n",
    "#     print(\"X y: \",X_train,y_train)\n",
    "    clf = linear_model.SGDClassifier()\n",
    "    coo,w1,w2,w3,w4=future_start(0,[[0,0],[0,0],[0,0],[0,0]],clf)\n",
    "    print(\"coo\",coo.result())\n",
    "    future=[coo,w1,w2,w3,w4]\n",
    "    while True:\n",
    "        status_l=[w1.status,w2.status,w3.status,w4.status]\n",
    "#         print(\"status: \",status_l)\n",
    "        if status_l.count('error')==len(status_l):\n",
    "            print(\"ERROR:\\n\",w1.traceback(),\"\\n with format:\\n\",traceback.format_tb(w1.traceback()) )\n",
    "        if status_l.count('finished')!=len(status_l):\n",
    "            if coo.status=='finished':\n",
    "                print(\"coo\",coo.result())\n",
    "                E=coo.result()[0]\n",
    "                del coo\n",
    "                coo= client.submit(coordinator,4,E,workers=worker1)\n",
    "\n",
    "        else:\n",
    "            print(\"End of chunks.For now on E will stay the same!\")\n",
    "            status_l=[coo.status,w1.status,w2.status,w3.status,w4.status]\n",
    "            print(status_l)\n",
    "            while coo.status!='finished':\n",
    "                time.sleep(0.01)\n",
    "            status_l=[coo.status,w1.status,w2.status,w3.status,w4.status]\n",
    "            print(status_l)\n",
    "            print(\"coo\",coo.result())\n",
    "            break\n",
    "        # here we will predict\n",
    "#         user_input = input(\"Enter: \") \n",
    "    \n",
    "    future=[coo,w1,w2,w3,w4]\n",
    "    for f in future: del f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coo (array([-137.40543803, -161.2029959 ,  137.37089331,   52.03545197]), 1, 1)\n",
      "coo (array([-137.40543803, -161.2029959 ,  137.37089331,   52.03545197]), 1, 1)\n",
      "coo (array([-110.3553591 , -241.3834686 ,  247.12209504,   67.59397969]), 1, 13)\n",
      "coo (array([ -60.23800098, -308.88879081,  351.39732924,   77.73393432]), 1, 1)\n",
      "coo (array([ -13.05362586, -384.82110553,  464.69925714,   90.1341545 ]), 1, 1)\n",
      "coo (array([  81.39877622, -420.71108929,  549.5833521 ,   88.18728099]), 1, 1)\n",
      "coo (array([ 183.52516684, -461.47196354,  643.75355544,   86.5329442 ]), 1, 1)\n",
      "coo (array([ 249.66748211, -541.90196823,  770.78545115,   97.91853753]), 1, 1)\n",
      "coo (array([ 345.91797522, -591.39737603,  873.08030422,   98.91384557]), 1, 1)\n",
      "coo (array([ 441.81428068, -640.710648  ,  974.9987273 ,   99.90549102]), 1, 1)\n",
      "coo (array([ 537.35899566, -689.84311972, 1076.54348062,  100.89350074]), 1, 1)\n",
      "coo (array([ 632.55468885, -738.79611208, 1177.71729421,  101.87790129]), 1, 1)\n",
      "coo (array([ 727.4039009 , -787.57093159, 1278.52286826,  102.85871895]), 1, 1)\n",
      "coo (array([ 810.91541149, -847.28474257, 1387.77583369,  107.58848789]), 1, 2)\n",
      "coo (array([ 893.82773635, -906.57011365, 1496.24492134,  112.28432127]), 1, 2)\n",
      "coo (array([ 959.93110209, -977.59549601, 1611.76461098,  121.50586907]), 1, 2)\n",
      "coo (array([ 1025.79985073, -1048.36879182,  1726.87429284,   130.69468734]), 1, 1)\n",
      "coo (array([ 1096.06084223, -1111.66213388,  1834.74852811,   137.68366487]), 1, 2)\n",
      "coo (array([ 1149.77410479, -1188.61043251,  1952.12744602,   149.61158285]), 1, 2)\n",
      "coo (array([ 1203.1140345 , -1265.02390369,  2068.69052437,   161.4565961 ]), 1, 2)\n",
      "coo (array([ 1272.65676328, -1332.09109597,  2180.86564227,   169.39337339]), 1, 2)\n",
      "coo (array([ 1317.26863589, -1409.05753756,  2294.31448414,   182.31040408]), 1, 2)\n",
      "coo (array([ 1379.13634932, -1473.69842819,  2400.19107456,   190.51836219]), 1, 3)\n",
      "coo (array([ 1452.79784928, -1525.12088848,  2495.03216363,   194.40248197]), 1, 3)\n",
      "coo (array([ 1528.33292202, -1576.51243623,  2590.6490618 ,   198.07672139]), 22, 1)\n",
      "coo (array([ 1528.33292202, -1576.51243623,  2590.6490618 ,   198.07672139]), 278, 2)\n",
      "End of chunks.For now on E will stay the same!\n",
      "['finished', 'finished', 'finished', 'finished', 'finished']\n",
      "['finished', 'finished', 'finished', 'finished', 'finished']\n",
      "coo (array([ 1528.33292202, -1576.51243623,  2590.6490618 ,   198.07672139]), 278, 2)\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Partial fit with the same data-compaire results\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X,y=get_chunk(2) #get_newSi(count_chunks,f_name)\n",
    "# if type(X)==str and type(y)==str:\n",
    "#     flag=False\n",
    "#     print(\"NO Chunks\")\n",
    "# clf.partial_fit(X,y,np.unique([0,1]))\n",
    "# return clf,clf.coef_,X_test,y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sys import getsizeof\n",
    "# def kati():\n",
    "#     clf = linear_model.SGDClassifier()\n",
    "#     X, y = make_classification(n_samples=1200, n_features=4,n_classes=2)\n",
    "#     X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "#     np.save(\"X\", X_train)\n",
    "#     np.save(\"y\", y_train)\n",
    "#     X,y=get_chunk(2) #get_newSi(count_chunks,f_name)\n",
    "#     if type(X)==str and type(y)==str:\n",
    "#         flag=False\n",
    "#         print(\"NO Chunks\")\n",
    "\n",
    "#     clf.partial_fit(X,y,np.unique([0,1]))\n",
    "#     return clf,clf.coef_,X_test,y_test\n",
    "# # getsizeof(clf),getsizeof(clf.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# clf1,coef,X_test,y_test=kati()\n",
    "# getsizeof(clf2),getsizeof(coef),clf2.coef_ , coef\n",
    "import sys\n",
    "from types import ModuleType, FunctionType\n",
    "from gc import get_referents\n",
    "\n",
    "# Custom objects know their class.\n",
    "# Function objects seem to know way too much, including modules.\n",
    "# Exclude modules as well.\n",
    "BLACKLIST = type, ModuleType, FunctionType\n",
    "\n",
    "\n",
    "def getsize(obj):\n",
    "    \"\"\"sum size of object & members.\"\"\"\n",
    "    if isinstance(obj, BLACKLIST):\n",
    "        raise TypeError('getsize() does not take argument of type: '+ str(type(obj)))\n",
    "    seen_ids = set()\n",
    "    size = 0\n",
    "    objects = [obj]\n",
    "    while objects:\n",
    "        need_referents = []\n",
    "        for obj in objects:\n",
    "            \n",
    "            if not isinstance(obj, BLACKLIST) and id(obj) not in seen_ids:\n",
    "                seen_ids.add(id(obj))\n",
    "                size += sys.getsizeof(obj)\n",
    "                need_referents.append(obj)\n",
    "        objects = get_referents(*need_referents)\n",
    "    return size\n",
    "\n",
    "#_______________________________Compaire size_____________________________________\n",
    "# all_s=getsize(coef)+getsize(clf2.intercept_)\n",
    "# intercept=clf1.intercept_[0].item()\n",
    "# coef_list=coef[0].tolist()\n",
    "# coef[0],coef_list,getsizeof(coef[0]),getsizeof(coef_list),getsizeof(clf1.intercept_[0]),getsizeof(intercept)\n",
    "\n",
    "\n",
    "# pyval = val.item()\n",
    "# print(type(pyval))\n",
    "#________________________________Compaire predict________________________________________\n",
    "# clf2=linear_model.SGDClassifier()\n",
    "# clf2=clf\n",
    "# clf2.coef_=clf1.coef_\n",
    "# clf2.intercept_=clf1.intercept_\n",
    "# # clf2.t_=clf1.t_\n",
    "\n",
    "# y_pred1 = clf1.predict(X_test)\n",
    "# y_pred2 = clf2.predict(X_test)\n",
    "# sys.stdout.write(\"\\nAccuracy: %f\" % (100*metrics.accuracy_score(y_test, y_pred1)))\n",
    "# sys.stdout.write(\"\\nAccuracy: %f\" % (100*metrics.accuracy_score(y_test, y_pred2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
